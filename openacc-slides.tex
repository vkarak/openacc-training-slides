\documentclass[12pt,aspectratio=169]{beamer}

\usetheme{CSCS}

% define footer text
\newcommand{\footlinetext}{CSCS-USI Summer School 2016}

% Select the image for the title page
\newcommand{\picturetitle}{cscs_images/image3.pdf}


% Please use the predifined colors:
% cscsred, cscsgrey, cscsgreen, cscsblue, cscsbrown, cscspurple, cscsyellow,
% cscsblack, cscswhite

\author{Vasileios Karakasis, CSCS}
\title{Introduction to OpenACC}
\subtitle{Summer School 2016 -- Effective High Performance Computing}
\date{July 27, 2016}

\begin{document}

% TITLE SLIDE
\cscstitle

% TABLE OF CONTENT SLIDE
% All options for table of contents:
% currentsection, currentsubsection, firstsection=xx, hideallsubsections, hideothersubsections, part=xx, pausesections, pausesubsections, sections=xx, sections={xx-yy}, sections={xx,yy}
%\cscstableofcontents[hideallsubsections]{Title}
\cscstableofcontents{Goals of this course}

% Pseudo-structure in order just to get into the TOC
\section{Part I}
\subsection{Quick overview of OpenACC}
\subsection{Deeper understanding of the concepts through hands-on examples}

\section{Part II}
\subsection{Port the miniapp to GPU using OpenACC}
\subsection{Walk away ready (or willing) to start hacking your own code}

\begin{frame}{What is OpenACC?}
  \begin{itemize}
  \item Collection of compiler directives for specifying loops and regions to be
    offloaded from a host CPU to an attached accelerator device
  \item Host + Accelerator programming model
  \item High-level representation
  \item Current specification version: 2.5
    \begin{itemize}
    \item 3.0 is scheduled this fall
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{When to use OpenACC?}
  In any of the following cases:
  \vspace\baselineskip
  \begin{itemize}
  \item I program in Fortran
  \item I need portability across different accelerator vendors
  \item I don't care about the details, I want my science done
  \item I want to run on accelerators, but I still need a readable code
  \item I inhereted a large legacy monolithic codebase, which I don't dare to
    refactor completely, but I need results faster
  \end{itemize}
\end{frame}

\begin{frame}{OpenACC is not a silver bullet}
  \begin{itemize}
  \item User base is still relatively small but expanding
    \begin{itemize}
    \item You may run into compiler bugs or specification ambiguities
    \end{itemize}
  \item A high-level representation is not a panacea
    \begin{itemize}
    \item You need to adapt to the programming model
    \end{itemize}
  \item Be ware of avoiding a \lstinlineCpp{\#pragma}-clutter
    \begin{itemize}
    \item Rethink and refactor
    \end{itemize}
  \item Does not substitute hand-tuning
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Format of directives}
  \begin{itemize}
  \item C/C++
    \begin{itemize}
    \item \lstinlineCpp{\#pragma acc} \emph{directive-name [clause-list]
      new-line}
    \item Scope is the following block of code
    \end{itemize}
  \item Fortran
    \begin{itemize}
    \item \lstinlineFortran{\!\$acc} \emph{directive-name [clause-list]
      new-line}
    \item Scope is until \lstinlineFortran{\!\$acc end} \emph{directive-name}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Programming model}
  \begin{itemize}
  \item Host-directed execution
  \item Compute intensive regions are offloaded to attached accelerator devices
  \item Host orchestrates the execution on the device
    \begin{itemize}
    \item Allocations on the device
    \item Data transfers
    \item Kernel launches
    \item Wait for events
    \item Etc\dots
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Execution model}
  \begin{itemize}
  \item The device executes \emph{parallel} or \emph{kernel regions}
  \item Parallel region
    \begin{itemize}
    \item Work-sharing loops
    \end{itemize}
  \item Kernel region
    \begin{itemize}
    \item Multiple loops to be executed as multiple kernels
    \end{itemize}
  \item Levels of parallelim
    \begin{enumerate}
    \item \emph{Gang} \onslide<2->{\emph{$\rightarrow$ CUDA block}}
    \item \emph{Worker} \onslide<2->{\emph{$\rightarrow$ CUDA warp}}
    \item \emph{Vector} \onslide<2->{\emph{$\rightarrow$ CUDA threads}}
    \end{enumerate}
    \begin{itemize}
    \item Parallelism levels are decided by the compiler but can be fine-tuned by
      the user
    \onslide<2->{
    \alert{\item Mapping to CUDA blocks/warps/threads is implementation defined}
    }
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Execution model}{Modes of execution}
  \begin{itemize}
  \item Gang
    \begin{itemize}
    \item Gang-redundant (GR)
    \item Gang-partioned (GP)
    \end{itemize}
  \item Worker
    \begin{itemize}
    \item Worker-single (WS)
    \item Worker-partitioned (WP)
    \end{itemize}
  \item Vector
    \begin{itemize}
    \item Vector-single (VS)
    \item Vector-partitioned (VP)
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{The \lstinlineCpp{kernels} construct}
  \begin{Fortranlisting}{Multiple loops inside kernels construct}
!$acc kernels
    !GR mode
    do i = 1, N
        !compiler decides on the partitioning (GP/WP/VP modes)
        y(i) = y(i) + a*x(i)
    enddo
    do i = 1, N
        !compiler decides on the partitioning (GP/WP/VP modes)
        y(i) = b*y(i) + a*x(i)
    enddo
!$acc end kernels
  \end{Fortranlisting}
  \begin{itemize}
  \item Compiler will try to deduce parallelism
  \item Loops are launched as different kernels
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{The \lstinlineCpp{parallel} construct}
  \begin{Fortranlisting}{Parallel construct}
!$acc parallel
    do i = 1, N
        ! loop executed in GR mode
        y(i) = y(i) + a*x(i)
    enddo
    !$acc loop
    do i = 1, N
        !compiler decides on the partitioning (GP/WP/VP modes)
        y(i) = b*y(i) + a*x(i)
    enddo
!$acc end parallel
  \end{Fortranlisting}
  \begin{itemize}
  \item No automatic parallelism deduction $\rightarrow$ parallel loops must
    be specified explicitly
  \item Implicit gang barrier at the end of \lstinlineCpp{parallel}
  \end{itemize}
\end{frame}

\begin{frame}{Execution model}{Work-sharing loops}
  \begin{itemize}
  \item C/C++: \lstinlineCpp{\#pragma acc loop}
    \begin{itemize}
    \item Applies to the immediately following \lstinlineCpp{for} loop
    \end{itemize}
  \item Fortran: \lstinlineFortran{\!\$acc loop}
    \begin{itemize}
    \item Applies to the immediately following \lstinlineCpp{do} loop
    \end{itemize}
  \item Loop will be automatically striped and assigned to different threads
    \begin{itemize}
    \item Use the \lstinlineCpp{independent} clause to force striping
    \end{itemize}
  \item Convenience syntax combines
    \lstinlineCpp{parallel}/\lstinlineCpp{kernels} and \lstinlineCpp{loop}
    constructs
    \begin{itemize}
    \item \lstinlineCpp{\#pragma acc parallel loop}
    \item \lstinlineCpp{\#pragma acc kernels loop}
    \item \lstinlineFortran{\!\$acc parallel loop}
    \item \lstinlineFortran{\!\$acc kernels loop}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{Controlling parallelism}
  \begin{itemize}
  \item Amount of parallelism at the \lstinlineCpp{kernels} and
    \lstinlineCpp{parallel} level
    \begin{itemize}
    \item \lstinlineCpp{num_gangs(...)}, \lstinlineCpp{num_workers(...)},
      \lstinlineCpp{vector_length(...)}
    \end{itemize}
  \item At the \lstinlineCpp{loop} level
    \begin{itemize}
    \item \lstinlineCpp{gang}, \lstinlineCpp{worker}, \lstinlineCpp{vector}
    \end{itemize}
  \end{itemize}

  \begin{Fortranlisting}{100 thread blocks with 128 threads each}
!$acc parallel num_gangs(100), vector_length(128)
    !$acc loop gang, vector
    do i = 1, n
        y(i) = y(i) + a*x(i)
    enddo
!$acc end parallel
  \end{Fortranlisting}

  %% Ideally, we want this to overlay with the listing above
  %% \begin{Fortranlisting}{100 thread blocks with 128 threads each}
  %%   !$acc parallel loop gang(100), vector(128)
  %%   do i = 1, n
  %%       y(i) = y(i) + a*x(i)
  %%   enddo
  %% \end{Fortranlisting}

  %% \item Synchronization
  %%   \begin{itemize}
  %%   \item Active queues (CUDA streams)
  %%     \begin{itemize}

  %%     \end{itemize}
  %%   \item Atomic operations with the \lstinlineFortran{\!\$acc atomic}
  %%   %% \item No \lstinlineCpp{__syncthreads()} or any kind of global synchronization
  %%   %%   \begin{itemize}
  %%   %%   \item Attempt to implement one based on atomics will likely fail
  %%   %%   \end{itemize}
  %%   \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{Synchronization \& Activity queues}
  \begin{itemize}
  \item Atomics
    \begin{itemize}
    \item \lstinlineCpp{\#pragma acc atomic} [atomic-clause]
    \item \lstinlineFortran{\!\$acc atomic} [atomic-clause]
    \item Atomic clauses: \lstinlineCpp{read}, \lstinlineCpp{write},
      \lstinlineCpp{update} and \lstinlineCpp{capture}
    \item Example of ``capturing'' a value:
      \begin{itemize}
      \item \lstinlineCpp{v = x++;}
      \end{itemize}
    \end{itemize}
  \item Activity queues (CUDA event queues)
    \begin{itemize}
    \item Data copies and kernels are launched synchronously inside the activity
      queues
    \item \lstinlineCpp{async} clause $\rightarrow$ pushes operations to
      an activity queue and host continues execution
    \item \lstinlineCpp{wait} clause $\rightarrow$ wait for \emph{pending}
      operations to finish in an activity queue
    \item \lstinlineCpp{\#pragma acc wait}
    \end{itemize}
  \item No \lstinlineCpp{__syncthreads()}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{Activity queues example}
  \begin{Cpplisting}{Launch multiple kernels asynchronously on the GPU}
// Launch kernel on GPU and continue on CPU
#pragma acc parallel loop async(1) present(a)
for(i = 0; i < N; ++i) {
  a[i] = // ... compute on GPU
}
// Launch another kernel on GPU and continue on CPU
#pragma acc parallel loop async(2) present(b)
for(j = 0; j < N; ++j) {
  b[j] = // ... compute on GPU
}
// Wait for all kernels to finish
#pragma acc wait
  \end{Cpplisting}
  \begin{itemize}
  \item Especially useful for overlapping data transfers and execution
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Memory model}{Where is my data?}
  \begin{itemize}
  \item \lstinlineCpp{\#pragma acc data} \emph{[data-clause]}
    \begin{itemize}
    \item Scope and lifetime is the immediately following block of code
    \end{itemize}
  \item \lstinlineCpp{\#pragma acc enter data} \emph{[data-clause]}
  \item \lstinlineCpp{\#pragma acc exit data} \emph{[data-clause]}
  \item Common clauses:
    \begin{itemize}
    \item \lstinlineCpp{create(a)}: Allocate array \lstinlineCpp{a} on device
      (\lstinlineCpp{data} and \lstinlineCpp{enter data} only)
    \item \lstinlineCpp{copyin(a)}: Copy array \lstinlineCpp{a} to device
      (\lstinlineCpp{data} and \lstinlineCpp{enter data} only)
    \item \lstinlineCpp{copyout(a)}: Copy array \lstinlineCpp{a} from device
      (\lstinlineCpp{data} and \lstinlineCpp{exit data} only)
    \item \lstinlineCpp{present(a)}: Inform OpenACC runtime that array
      \lstinlineCpp{a} is on device
      (\lstinlineCpp{data} only)
    \item \lstinlineCpp{delete(a)}: Deallocate array \lstinlineCpp{a} from
      device (\lstinlineCpp{exit data} only)
    \item \lstinlineCpp{wait}, \lstinlineCpp{async}: \lstinlineCpp{enter data}
      and \lstinlineCpp{exit data} only
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Memory model}{Specifying array ranges}
  \begin{itemize}
  \item Whole arrays
    \begin{itemize}
    \item C/C++: You \emph{must} specify bounds for dynamically allocated arrays
      \begin{itemize}
      \item \lstinlineCpp{\#pragma acc data copyin(a[0:n])}
      \end{itemize}
    \item Fortran: array shape information is already embedded in the data type
      \begin{itemize}
      \item \lstinlineFortran{\!\$acc data copyin(a)}
      \end{itemize}
    \end{itemize}
  \item Array subranges
    \begin{itemize}
    \item \lstinlineCpp{\#pragma acc data copyin(a[2:n-2])}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Memory model}{Deep copy}
  \begin{Cpplisting}{Deep copy example}
struct foo {
    int *array;
    size_t len;
};
foo a[10];
for (int i = 0; i < 10; ++i) {
    a.len = 100;
    a.array = new int[a.len];
}
#pragma acc enter data copyin(a[0:10])
  \end{Cpplisting}
  \begin{itemize}
  \item What will be copied over to the device? \onslide<2->{$\rightarrow$ just
    \lstinlineCpp{a} with dangling \lstinlineCpp{array} pointers :-(}
  \item What you would like to be copied? \onslide<3->{$\rightarrow$
    everything, you must wait for OpenACC 3.0}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Combining it all}
\end{frame}


\begin{frame}{Hands-on}{axpy}

\end{frame}


\begin{frame}{Hands-on}{Reduction}

\end{frame}

\begin{frame}{Data management}

\end{frame}

\begin{frame}{Hands-on}{Blur kernel}

\end{frame}

\begin{frame}{Interoperability with CUDA and MPI}

\end{frame}

\begin{frame}{Hands-on}{The diffusion kernel}

\end{frame}

% Programming model (data and compute regions)
% Form of the directives + reduction
% First hands-on example axpy + reduction
% Separate data regions and compute regions
% Hands-on blur example (naive + no unnecessary copies)
% Interoperability with CUDA
% Hands-on diffusion
% OpenACC outlook and comparison with OpenMP 4 and 4.5

% Part II -- Porting the miniapp
% Talk about the structure of the application, especially the Field class
% Revisit the enter/exit data directives
% Describe the porting approach step-by-step
% 1. Field, 2. linalg, 3. operators, 4. rest

% THANK YOU SLIDE
\cscsthankyou{Thank you for your attention.}

\end{document}
