\documentclass[12pt,aspectratio=169]{beamer}

\usetheme{CSCS}

% define footer text
\newcommand{\footlinetext}{CSCS-USI Summer School 2016}

% Select the image for the title page
\newcommand{\picturetitle}{cscs_images/image3.pdf}


% Please use the predifined colors:
% cscsred, cscsgrey, cscsgreen, cscsblue, cscsbrown, cscspurple, cscsyellow,
% cscsblack, cscswhite

\author{Vasileios Karakasis, CSCS}
\title{Introduction to OpenACC}
\subtitle{Summer School 2016 -- Effective High Performance Computing}
\date{July 27, 2016}

\begin{document}

% TITLE SLIDE
\cscstitle

% TABLE OF CONTENT SLIDE
% All options for table of contents:
% currentsection, currentsubsection, firstsection=xx, hideallsubsections, hideothersubsections, part=xx, pausesections, pausesubsections, sections=xx, sections={xx-yy}, sections={xx,yy}
%\cscstableofcontents[hideallsubsections]{Title}
\cscstableofcontents{Goals of this course}

% Pseudo-structure in order just to get into the TOC
\section{Part I}
\subsection{Quick overview of OpenACC}
\subsection{Deeper understanding of the concepts through hands-on examples}

\section{Part II}
\subsection{Port the miniapp to GPU using OpenACC}
\subsection{Walk away ready to start hacking your own code}

\begin{frame}{What is OpenACC?}
  \begin{itemize}
  \item Collection of compiler directives for specifying loops and regions to be
    offloaded from a host CPU to an attached accelerator device
  \item Host + Accelerator programming model
  \item High-level representation
  \item Current specification version: 2.5
    \begin{itemize}
    \item 3.0 is scheduled this fall
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{When to use OpenACC?}
  In any of the following cases:
  \vspace\baselineskip
  \begin{itemize}
  \item I program in Fortran
  \item I need portability across different accelerator vendors
  \item I don't care about the details, I want my science done
  \item I want to run on accelerators, but I still need a readable code
  \item I inhereted a large legacy monolithic codebase, which I don't dare to
    refactor completely, but I need results faster
  \end{itemize}
\end{frame}

\begin{frame}{OpenACC is not a silver bullet}
  \begin{itemize}
  \item User base is still relatively small but expanding
    \begin{itemize}
    \item You may run into compiler bugs or specification ambiguities
    \end{itemize}
  \item A high-level representation is not a panacea
    \begin{itemize}
    \item You need to adapt to the programming model
    \end{itemize}
  \item Be ware of avoiding a \lstinlineCpp{\#pragma}-clutter
    \begin{itemize}
    \item Rethink and refactor
    \end{itemize}
  \item Does not substitute hand-tuning
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Format of directives}
  \begin{itemize}
  \item C/C++
    \begin{itemize}
    \item \lstinlineCpp{\#pragma acc} \emph{directive-name [clause-list]
      new-line}
    \item Scope is the following block of code
    \end{itemize}
  \item Fortran
    \begin{itemize}
    \item \lstinlineFortran{\!\$acc} \emph{directive-name [clause-list]
      new-line}
    \item Scope is until \lstinlineFortran{\!\$acc end} \emph{directive-name}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Programming model}
  \begin{itemize}
  \item Host-directed execution
  \item Compute intensive regions are offloaded to attached accelerator devices
  \item Host orchestrates the execution on the device
    \begin{itemize}
    \item Allocations on the device
    \item Data transfers
    \item Kernel launches
    \item Wait for events
    \item Etc\dots
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Execution model}
  \begin{itemize}
  \item The device executes \emph{parallel} or \emph{kernel regions}
  \item Parallel region
    \begin{itemize}
    \item Work-sharing loops
    \end{itemize}
  \item Kernel region
    \begin{itemize}
    \item Multiple loops to be executed as multiple kernels
    \end{itemize}
  \item Levels of parallelim
    \begin{enumerate}
    \item \emph{Gang} \onslide<2->{\emph{$\rightarrow$ CUDA block}}
    \item \emph{Worker} \onslide<2->{\emph{$\rightarrow$ CUDA warp}}
    \item \emph{Vector} \onslide<2->{\emph{$\rightarrow$ CUDA threads}}
    \end{enumerate}
    \begin{itemize}
    \item Parallelism levels are decided by the compiler but can be fine-tuned by
      the user
    \onslide<2->{
    \alert{\item Mapping to CUDA blocks/warps/threads is implementation defined}
    }
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Execution model}{Modes of execution}
  \begin{itemize}
  \item Gang
    \begin{itemize}
    \item Gang-redundant (GR)
    \item Gang-partioned (GP)
    \end{itemize}
  \item Worker
    \begin{itemize}
    \item Worker-single (WS)
    \item Worker-partitioned (WP)
    \end{itemize}
  \item Vector
    \begin{itemize}
    \item Vector-single (VS)
    \item Vector-partitioned (VP)
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{The \lstinlineCpp{kernels} construct}
  \begin{Fortranlisting}{Multiple loops inside kernels construct}
!$acc kernels
    !GR mode
    do i = 1, N
        !compiler decides on the partitioning (GP/WP/VP modes)
        y(i) = y(i) + a*x(i)
    enddo
    do i = 1, N
        !compiler decides on the partitioning (GP/WP/VP modes)
        y(i) = b*y(i) + a*x(i)
    enddo
!$acc end kernels
  \end{Fortranlisting}
  \begin{itemize}
  \item Compiler will try to deduce parallelism
  \item Loops are launched as different kernels
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{The \lstinlineCpp{parallel} construct}
  \begin{Fortranlisting}{Parallel construct}
!$acc parallel
    do i = 1, N
        ! loop executed in GR mode
        y(i) = y(i) + a*x(i)
    enddo
    !$acc loop
    do i = 1, N
        !compiler decides on the partitioning (GP/WP/VP modes)
        y(i) = b*y(i) + a*x(i)
    enddo
!$acc end parallel
  \end{Fortranlisting}
  \begin{itemize}
  \item No automatic parallelism deduction $\rightarrow$ parallel loops must
    be specified explicitly
  \item Implicit gang barrier at the end of \lstinlineCpp{parallel}
  \end{itemize}
\end{frame}

\begin{frame}{Execution model}{Work-sharing loops}
  \begin{itemize}
  \item C/C++: \lstinlineCpp{\#pragma acc loop}
    \begin{itemize}
    \item Applies to the immediately following \lstinlineCpp{for} loop
    \end{itemize}
  \item Fortran: \lstinlineFortran{\!\$acc loop}
    \begin{itemize}
    \item Applies to the immediately following \lstinlineCpp{do} loop
    \end{itemize}
  \item Loop will be automatically striped and assigned to different threads
    \begin{itemize}
    \item Use the \lstinlineCpp{independent} clause to force striping
    \end{itemize}
  \item Convenience syntax combines
    \lstinlineCpp{parallel}/\lstinlineCpp{kernels} and \lstinlineCpp{loop}
    constructs
    \begin{itemize}
    \item \lstinlineCpp{\#pragma acc parallel loop}
    \item \lstinlineCpp{\#pragma acc kernels loop}
    \item \lstinlineFortran{\!\$acc parallel loop}
    \item \lstinlineFortran{\!\$acc kernels loop}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{Work-sharing loops -- the \lstinlineCpp{collapse} clause}
  \begin{Fortranlisting}{Collapse loops}
!$acc loop collapse(2)
do i = 1,N
    do j = 1,N
        A(i,j) = coeff*B(i,j)
    enddo
enddo
  \end{Fortranlisting}
  \begin{itemize}
  \item OpenACC vs.\ OpenMP
    \begin{itemize}
    \item OpenACC: apply the \lstinlineCpp{loop} directive to the following $N$
      loops and possibly collapse their iteration spaces if independent
    \item OpenMP: Collapse the iteration spaces of the following $N$ loops
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{Controlling parallelism}
  \begin{itemize}
  \item Amount of parallelism at the \lstinlineCpp{kernels} and
    \lstinlineCpp{parallel} level
    \begin{itemize}
    \item \lstinlineCpp{num_gangs(...)}, \lstinlineCpp{num_workers(...)},
      \lstinlineCpp{vector_length(...)}
    \end{itemize}
  \item At the \lstinlineCpp{loop} level
    \begin{itemize}
    \item \lstinlineCpp{gang}, \lstinlineCpp{worker}, \lstinlineCpp{vector}
    \end{itemize}
  \end{itemize}

  \begin{Fortranlisting}{100 thread blocks with 128 threads each}
!$acc parallel num_gangs(100), vector_length(128)
    !$acc loop gang, vector
    do i = 1, n
        y(i) = y(i) + a*x(i)
    enddo
!$acc end parallel
  \end{Fortranlisting}
\end{frame}

\begin{frame}[fragile]{Execution model}{Calling functions from parallel regions}
  \begin{itemize}
  \item \lstinlineCpp{\#pragma acc routine \{gang | worker | vector | seq\}}
    \begin{itemize}
    \item Just before the function declaration or definition
    \end{itemize}
  \item \lstinlineFortran{\!\$acc routine \{gang | worker | vector | seq\}}
    \begin{itemize}
    \item In the specification part of the subroutine
    \end{itemize}
  \item Parallelism level of the routine
    \begin{itemize}
    \item \lstinlineCpp{gang}: must be called from GR context
    \item \lstinlineCpp{worker}: must be called from WS context
    \item \lstinlineCpp{vector}: must be called from VS context
    \item \lstinlineCpp{seq}: must be called from sequential context
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{Synchronization \& Activity queues}
  \begin{itemize}
  \item Atomics
    \begin{itemize}
    \item \lstinlineCpp{\#pragma acc atomic} [atomic-clause]
    \item \lstinlineFortran{\!\$acc atomic} [atomic-clause]
    \item Atomic clauses: \lstinlineCpp{read}, \lstinlineCpp{write},
      \lstinlineCpp{update} and \lstinlineCpp{capture}
    \item Example of ``capturing'' a value:
      \begin{itemize}
      \item \lstinlineCpp{v = x++;}
      \end{itemize}
    \end{itemize}
  \item Activity queues (CUDA event queues)
    \begin{itemize}
    \item Data copies and kernels are launched synchronously inside the activity
      queues
    \item \lstinlineCpp{async} clause $\rightarrow$ pushes operations to
      an activity queue and host continues execution
    \item \lstinlineCpp{wait} clause $\rightarrow$ wait for \emph{pending}
      operations to finish in an activity queue
    \item \lstinlineCpp{\#pragma acc wait}
    \end{itemize}
  \item No \lstinlineCpp{__syncthreads()}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{Activity queues example}
  \begin{Cpplisting}{Launch multiple kernels asynchronously on the GPU}
// Launch kernel on GPU and continue on CPU
#pragma acc parallel loop async(1) present(a)
for(i = 0; i < N; ++i) {
  a[i] = // ... compute on GPU
}
// Launch another kernel on GPU and continue on CPU
#pragma acc parallel loop async(2) present(b)
for(j = 0; j < N; ++j) {
  b[j] = // ... compute on GPU
}
// Wait for all kernels to finish
#pragma acc wait
  \end{Cpplisting}
  \begin{itemize}
  \item Especially useful for overlapping data transfers and execution
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Memory model}{Where is my data?}
  \begin{itemize}
  \item \lstinlineCpp{\#pragma acc data} \emph{[data-clause]}
    \begin{itemize}
    \item Scope and lifetime is the immediately following block of code
    \end{itemize}
  \item \lstinlineCpp{\#pragma acc enter data} \emph{[data-clause]}
  \item \lstinlineCpp{\#pragma acc exit data} \emph{[data-clause]}
  \item Common clauses:
    \begin{itemize}
    \item \lstinlineCpp{create(a)}: Allocate array \lstinlineCpp{a} on device
      (\lstinlineCpp{data} and \lstinlineCpp{enter data} only)
    \item \lstinlineCpp{copyin(a)}: Copy array \lstinlineCpp{a} to device
      (\lstinlineCpp{data} and \lstinlineCpp{enter data} only)
    \item \lstinlineCpp{copyout(a)}: Copy array \lstinlineCpp{a} from device
      (\lstinlineCpp{data} and \lstinlineCpp{exit data} only)
    \item \lstinlineCpp{copy(a)}: Copy array \lstinlineCpp{a} to and from device
      (\lstinlineCpp{data} only)
    \item \lstinlineCpp{present(a)}: Inform OpenACC runtime that array
      \lstinlineCpp{a} is on device
      (\lstinlineCpp{data} only)
    \item \lstinlineCpp{delete(a)}: Deallocate array \lstinlineCpp{a} from
      device (\lstinlineCpp{exit data} only)
    \item \lstinlineCpp{wait}, \lstinlineCpp{async}: \lstinlineCpp{enter data}
      and \lstinlineCpp{exit data} only
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Memory model}{Array ranges and shared memory}
  \begin{itemize}
  \item Whole arrays
    \begin{itemize}
    \item C/C++: You \emph{must} specify bounds for dynamically allocated arrays
      \begin{itemize}
      \item \lstinlineCpp{\#pragma acc data copyin(a[0:n])}
      \end{itemize}
    \item Fortran: array shape information is already embedded in the data type
      \begin{itemize}
      \item \lstinlineFortran{\!\$acc data copyin(a)}
      \end{itemize}
    \end{itemize}
  \item Array subranges
    \begin{itemize}
    \item \lstinlineCpp{\#pragma acc data copyin(a[2:n-2])}
    \end{itemize}
  \item Hint that a subarray should reside in the shared memory of the device
    \begin{itemize}
    \item \lstinlineCpp{\#pragma acc cache(<varlist>)}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Memory model}{Deep copy}
  \begin{Cpplisting}{Deep copy example}
struct foo {
    int *array;
    size_t len;
};
foo a[10];
for (int i = 0; i < 10; ++i) {
    a.len = 100;
    a.array = new int[a.len];
}
#pragma acc enter data copyin(a[0:10])
  \end{Cpplisting}
  \begin{itemize}
  \item What will be copied over to the device? \onslide<2->{$\rightarrow$ just
    \lstinlineCpp{a} with dangling \lstinlineCpp{array} pointers :-(}
  \item<3-> What you would like to be copied? $\rightarrow$
    everything, you must wait for OpenACC 3.0
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Combining it all}
  \begin{Cpplisting}{Data movement/Activity queues/Parallel loops}
// prepare array a on host
#pragma acc enter data async(1) copyin(a[0:N])
// prepare array b on host
#pragma acc enter data async(2) copyin(b[0:N])
#pragma acc parallel loop async(1) present(a[0:N])
for (i = 0; i < N: ++i)
    foo(a[i])

#pragma acc exit data copyout(a[0:N]) async(1)
#pragma acc parallel loop async(2) present(b[0:N])
for (i = 0; i < N; ++i)
    bar(b[i])
#pragma acc exit data copyout(b[0:N]) async(2)
// some more stuff on the host and then wait for all streams to finish
#pragma acc wait

  \end{Cpplisting}
\end{frame}

\begin{frame}[fragile]{Profiling}
  \begin{itemize}
  \item NVIDIA tools (nvprof, nvpp)
    \begin{itemize}
    \item \lstinlineCpp{\$ nvprof <openacc-executable>}
    \end{itemize}
  \item CrayPAT
    \begin{itemize}
    \item \lstinlineCpp{\$ module load perftools-cscs/630openacc}
    \item Recompile and run
    \item Report in \lstinlineCpp{.rpt} file
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Hands-on}{axpy}
  \begin{itemize}
  \item \lstinlineCpp{exercises/openacc/axpy/axpy_openacc.\{cpp,f90\}}
  \item \lstinlineCpp{grep TODO *.\{cpp,f90,f03\}}
  \item \lstinlineCpp{module load craype-accel-nvidia35}
  \item \lstinlineCpp{module switch cce/8.3.12 cce/8.4.6}
  \item \lstinlineCpp{module switch pgi/15.3.0 pgi/15.9.0}
  \item \lstinlineCpp{make VERBOSE=1 PGI=1} or \lstinlineCpp{CRAY=1}
  \end{itemize}
\end{frame}

\begin{frame}{Hands-on}{Reduction}
  \begin{itemize}
  \item \lstinlineCpp{\#pragma acc parallel reduction(<op>:<var>)}
    \begin{itemize}
    \item e.g., \lstinlineCpp{\#pragma acc parallel reduction(+:sum)}
    \end{itemize}
  \item \lstinlineCpp{\#pragma acc loop reduction(<op>:<var>)}
  \item \lstinlineCpp{var} must be scalar
  \item \lstinlineCpp{var} is copied and default initialized within each gang
    and/or thread
  \item Intermediate results from each gang are combined and made available
    outside the parallel region
  \item \lstinlineCpp{exercises/openacc/shared/dot_openacc.\{cpp,f90\}}
  \end{itemize}
\end{frame}

\begin{frame}{Data management}
  \begin{itemize}
  \item Moving data to and from the device is slow ($\approx$7--8\,GB/s per
    direction)
  \item Avoid unnecessary data movement
    \begin{itemize}
    \item Move needed data to GPU early enough and keep it there as long as
      possible
    \item Update host copies using \lstinlineCpp{\#pragma acc update} directive
      if needed
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Hands-on}{Blur kernel}
  \begin{Cpplisting}{Naive implementation}
for (auto istep = 0; istep < nsteps; ++istep) {
    int i;

    #pragma acc parallel loop copyin(in[0:n]) copyout(buffer[0:n])
    for(i=1; i<n-1; ++i) {
        buffer[i] = blur(i, in);
    }
    #pragma acc parallel loop copyin(buffer[0:n]) copy(out[0:n])
    for(i=2; i<n-2; ++i) {
        out[i] = blur(i, buffer);
    }

    std::swap(in, out);
}
  \end{Cpplisting}
\end{frame}

\begin{frame}[fragile]{Interoperability with MPI and CUDA}
  \begin{enumerate}
  \item Call an optimised library function that expects data on the device,
    e.g., cuBLAS
  \item Let optimised MPI implementations do RDMA between remote devices' memory
  \item Manual data management with CUDA, but parallelisation with OpenACC
    \begin{itemize}
    \item The safest way to manipulate pointers on the device
    \end{itemize}
  \end{enumerate}
  \onslide<2->{
    \begin{red2block}{Scenarios (1) and (2)}
      \lstinlineCpp{\#pragma acc host\_data use\_device(<varlist>)}
    \end{red2block}
  }
  \onslide<3->{
    \begin{red2block}{Scenario (3)}
      Use the \lstinlineCpp{deviceptr(<ptrlist>)} clause with
      \lstinlineCpp{parallel}, \lstinlineCpp{kernels} and \lstinlineCpp{data}
    \end{red2block}
  }
\end{frame}

\begin{frame}{Hands-on}{The diffusion kernel}
  \begin{itemize}
  \item \lstinlineCpp{exercises/openacc/diffusion/diffusion_omp.cpp}
  \item \lstinlineCpp{exercises/openacc/diffusion/diffusion_openacc.\{cpp,f90\}}
  \item \lstinlineCpp{exercises/openacc/diffusion/diffusion_openacc_mpi.\{cpp,f90\}}
  \item \lstinlineCpp{-DOPENACC_DATA} $\rightarrow$ data management by OpenACC
  \end{itemize}
\end{frame}

\begin{frame}{Future prospects}
  \begin{itemize}
  \item OpenACC 3.0 is coming
    \begin{itemize}
    \item Deep copy of data structures
    \item Better semantics for the \lstinlineCpp{reduction} clause
    \item Math function intrinsics
    \item Several other smaller scale improvements
    \end{itemize}
  \item OpenACC vs.\ OpenMP 4.0 and 4.5
    \begin{itemize}
    \item There is no merger envisioned right now
    \item PGI and NVIDIA are actively supporting OpenACC
    \item Cray abandons OpenACC development, but will provide support up to
      OpenACC 2.5
    \item GCC 5 supports OpenACC 2.0a
    \item Pathscale supports OpenACC 2.0
    \item Intel and OpenACC? -- No such thoughts
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{More information and events}
  \begin{itemize}
  \item \url{http://www.openacc.org}
  \item OpenACC Hackathons
    \begin{itemize}
    \item One week of intensive development for porting your code to the GPUs
    \item 5 developers + 2 mentors per team
    \item 2$\times$ in USA + 2$\times$ in Europe per year
    \item Find the one that fits you and apply!
    \end{itemize}
  \end{itemize}
\end{frame}

\part{Porting the miniapp to GPUs using OpenACC}

\begin{frame}[fragile]{General info}
  \begin{itemize}
  \item Fortran 90 version
    \begin{itemize}
    \item \lstinlineCpp{miniapp/openacc/fortran/}
    \end{itemize}
  \item C++11 version
    \begin{itemize}
    \item \lstinlineCpp{miniapp/openacc/cxx/}
    \item Compile with PGI 15.9
    \end{itemize}
  \item Interesting files
    \begin{itemize}
    \item\lstinlineCpp{main.\{cpp,f90\}}: the solver
    \item\lstinlineCpp{data.\{h,f90\}}: domain types
    \item\lstinlineCpp{linalg.\{cpp,f90\}}: linear algebra kernels
    \item\lstinlineCpp{operators.\{cpp,f90\}}: the diffusion kernel
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Notes for the C++ version}
  \begin{itemize}
  \item There are two C++-isms that complicate things:
    \begin{enumerate}
    \item Domain data is encapsulated inside the \lstinlineCpp{Field} class
      \begin{itemize}
      \item Allocated and initialised inside the constructor
      \item Deallocated inside the destructor
      \end{itemize}
    \item Operators for accessing the domain data
    \end{enumerate}
  \item[+] OpenACC provides the \lstinlineCpp{enter data} and \lstinlineCpp{exit
    data} directives for unscoped data management
  \item[+] Operators are just another kind of functions
    \begin{itemize}
    \item \lstinlineCpp{acc routine} directive is just for that
    \end{itemize}
  \item[+] Remember to copy the object itself (\lstinlineCpp{this} pointer)
  \end{itemize}
\end{frame}

\end{document}
