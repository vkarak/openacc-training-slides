\documentclass[12pt,aspectratio=169]{beamer}

\usetheme{CSCS}

% define footer text
\newcommand{\footlinetext}{CSCS-USI Summer School 2016}

% Select the image for the title page
\newcommand{\picturetitle}{cscs_images/image3.pdf}


% Please use the predifined colors:
% cscsred, cscsgrey, cscsgreen, cscsblue, cscsbrown, cscspurple, cscsyellow,
% cscsblack, cscswhite

\author{Vasileios Karakasis, CSCS}
\title{Introduction to OpenACC}
\subtitle{Summer School 2016 -- Effective High Performance Computing}
\date{July 27, 2016}

\begin{document}

% TITLE SLIDE
\cscstitle

% TABLE OF CONTENT SLIDE
% All options for table of contents:
% currentsection, currentsubsection, firstsection=xx, hideallsubsections, hideothersubsections, part=xx, pausesections, pausesubsections, sections=xx, sections={xx-yy}, sections={xx,yy}
%\cscstableofcontents[hideallsubsections]{Title}
\cscstableofcontents{Goals of this course}

% Pseudo-structure in order just to get into the TOC
\section{Part I}
\subsection{Quick overview of OpenACC}
\subsection{Deeper understanding of the concepts through hands-on examples}

\section{Part II}
\subsection{Port the miniapp to GPU using OpenACC}
\subsection{Walk away ready (or willing) to start hacking your own code}

\begin{frame}{What is OpenACC?}
  \begin{itemize}
  \item Collection of compiler directives for specifying loops and regions to be
    offloaded from a host CPU to an attached accelerator device
  \item Host + Accelerator programming model
  \item High-level representation
  \end{itemize}
\end{frame}

\begin{frame}{When to use OpenACC?}
  In any of the following cases:
  \vspace\baselineskip
  \begin{itemize}
  \item I program in Fortran
  \item I need portability across different accelerator vendors
  \item I don't care about the details, I want my science done
  \item I want to run on accelerators, but I still need a readable code
  \item I inhereted a large legacy monolithic codebase, which I don't dare to
    refactor completely, but I need results faster
  \end{itemize}
\end{frame}

\begin{frame}{OpenACC is not a silver bullet}
  \begin{itemize}
  \item User base is still relatively small but expanding
    \begin{itemize}
    \item You may run into compiler bugs or specification ambiguities
    \end{itemize}
  \item A high-level representation is not a panacea
    \begin{itemize}
    \item You need to adapt to the programming model
    \end{itemize}
  \item Be ware of avoiding a \lstinlineCpp{\#pragma}-clutter
    \begin{itemize}
    \item Rethink and refactor
    \end{itemize}
  \item Does not substitute hand-tuning
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Format of directives}
  \begin{itemize}
  \item C/C++
    \begin{itemize}
    \item \lstinlineCpp{\#pragma acc} \emph{directive-name [clause-list]
      new-line}
    \item Scope is the following block of code
    \end{itemize}
  \item Fortran
    \begin{itemize}
    \item \lstinlineFortran{\!\$acc} \emph{directive-name [clause-list]
      new-line}
    \item Scope is the following block of code or until\dots
    \item \lstinlineFortran{\!\$acc end} \emph{directive-name}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Programming model}
  \begin{itemize}
  \item Host-directed execution
  \item Compute intensive regions are offloaded to attached accelerator devices
  \item Host orchestrates the execution on the device
    \begin{itemize}
    \item Allocations on the device
    \item Data transfers
    \item Kernel launches
    \item Wait for events
    \item Etc\dots
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Execution model}
  \begin{itemize}
  \item The device executes \emph{parallel} or \emph{kernel regions}
  \item Parallel region
    \begin{itemize}
    \item Work-sharing loops
    \end{itemize}
  \item Kernel region
    \begin{itemize}
    \item Multiple loops to be executed as multiple kernels
    \end{itemize}
  \item Levels of parallelim
    \begin{enumerate}
    \item \emph{Gang} \onslide<2->{\emph{$\rightarrow$ CUDA block}}
    \item \emph{Worker} \onslide<2->{\emph{$\rightarrow$ CUDA warp}}
    \item \emph{Vector} \onslide<2->{\emph{$\rightarrow$ CUDA threads}}
    \end{enumerate}
    \begin{itemize}
    \item Parallelism levels are decided by the compiler but can be fine-tuned by
      the user
    \onslide<2->{
    \alert{\item Mapping to CUDA blocks/warps/threads is implementation defined}
    }
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Execution model}{Modes of execution}
  \begin{itemize}
  \item Gang
    \begin{itemize}
    \item Gang-redundant (GR)
    \item Gang-partioned (GP)
    \end{itemize}
  \item Worker
    \begin{itemize}
    \item Worker-single (WS)
    \item Worker-partitioned (WP)
    \end{itemize}
  \item Vector
    \begin{itemize}
    \item Vector-single (VS)
    \item Vector-partitioned (VP)
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{The \lstinlineCpp{kernels} construct}
  \begin{Fortranlisting}{Multiple loops inside kernels construct}
!$acc kernels
    !GR mode
    do i = 1, N
        !compiler decides on the partitioning (GP/WP/VP modes)
        y(i) = y(i) + a*x(i)
    enddo
    do i = 1, N
        !compiler decides on the partitioning (GP/WP/VP modes)
        y(i) = b*y(i) + a*x(i)
    enddo
!$acc end kernels
  \end{Fortranlisting}
  \begin{itemize}
  \item Compiler will try to deduce parallelism
  \item Loops are launched as different kernels
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Execution model}{The \lstinlineCpp{parallel} construct}
  \begin{Fortranlisting}{Parallel construct}
!$acc parallel
    do i = 1, N
        ! loop executed in GR mode
        y(i) = y(i) + a*x(i)
    enddo
    !$acc loop
    do i = 1, N
        !compiler decides on the partitioning (GP/WP/VP modes)
        y(i) = b*y(i) + a*x(i)
    enddo
!$acc end parallel
  \end{Fortranlisting}
  \begin{itemize}
  \item No automatic parallelism deduction $\rightarrow$ parallel loops must
    be specified explicitly
  \item Implicit barrier at the end of \lstinlineCpp{parallel}
  \end{itemize}
\end{frame}

\begin{frame}{Execution model}{Work-sharing loops}
\end{frame}

\begin{frame}{Memory model}{Where is my data?}

\end{frame}

\begin{frame}{Hands-on}{axpy}

\end{frame}


\begin{frame}{Hands-on}{Reduction}

\end{frame}

\begin{frame}{Data management}

\end{frame}

\begin{frame}{Hands-on}{Blur kernel}

\end{frame}

\begin{frame}{Interoperability with CUDA and MPI}

\end{frame}

\begin{frame}{Hands-on}{The diffusion kernel}

\end{frame}

% Programming model (data and compute regions)
% Form of the directives + reduction
% First hands-on example axpy + reduction
% Separate data regions and compute regions
% Hands-on blur example (naive + no unnecessary copies)
% Interoperability with CUDA
% Hands-on diffusion
% OpenACC outlook and comparison with OpenMP 4 and 4.5

% Part II -- Porting the miniapp
% Talk about the structure of the application, especially the Field class
% Revisit the enter/exit data directives
% Describe the porting approach step-by-step
% 1. Field, 2. linalg, 3. operators, 4. rest

% THANK YOU SLIDE
\cscsthankyou{Thank you for your attention.}

\end{document}
